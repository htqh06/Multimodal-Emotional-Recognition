# Multimodal-Emotional-Recognition
## Incomplete Multimodal Sentiment Recognition in the Case of Missing Partial Modalities 
· Developed a multimodal sentiment recognition system capable of handling partial modality loss.   
· Processing multimodal datasets IEMOCAP and MSP-IMPROV, including text, speech, and video, to extract relevant features.   
· Using TextCNN and LSTM for extracting features on text, speech and video modalities.   
· Inference of missing modal data based on the connections between different modal feature vectors using Cascaded Residual Autoencoders which connected with multiple residual autoencoder to improve the accuracy of data rebuild.   
· Applying forward propagation and backpropagation for mutual supervision to improve the accuracy of data reconstruction.   
·Design a UI based on PyQt that allows users to upload video, text, or audio files and receive emotion recognition results. 
